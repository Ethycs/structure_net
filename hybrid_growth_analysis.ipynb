{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517f1511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m⠁\u001b[0m activating environment                                                                 \u001b[32m⠁\u001b[0m                                                                               Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "🔄 Neuron sorting: Enabled (every 2 steps)\n",
      "🔬 Loading pretrained model from: ./data/promising_models/20250707_020152/model_cifar10_3layers_seed9_acc0.47_patch0.345_sparse0.050_BEST_ACCURACY_GLOBAL.pt\n",
      "/home/rabbit/structure_net/./experiments/hybrid_growth_experiment.py:578: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "   🎯 Using sparsity from checkpoint: 0.05\n",
      "   🏗️  Architecture: [3072, 2048, 10]\n",
      "   📊 Sparsity: 0.05\n",
      "   🔍 Available state dict keys:\n",
      "      0.linear.bias: torch.Size([2048])\n",
      "      0.linear.weight: torch.Size([2048, 3072])\n",
      "      0.mask: torch.Size([2048, 3072])\n",
      "      2.linear.bias: torch.Size([10])\n",
      "      2.linear.weight: torch.Size([10, 2048])\n",
      "      2.mask: torch.Size([10, 2048])\n",
      "   ✅ Loading pretrained weights for layer 0 (keys '0.linear.weight', '0.linear.bias')\n",
      "      ✅ Loaded original mask: 315349.0/6291456 connections\n",
      "   ✅ Loading pretrained weights for layer 1 (keys '2.linear.weight', '2.linear.bias')\n",
      "      ✅ Loaded original mask: 1082.0/20480 connections\n",
      "🧪 Testing initial accuracy...\n",
      "   🔍 Debug: Input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Expected input dim: 3072\n",
      "   🔍 Debug: Target shape: torch.Size([64])\n",
      "   🔍 Debug: Layer 0 input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Layer 0 weight shape: torch.Size([2048, 3072])\n",
      "   🔍 Debug: Layer 0 mask sum: 315349.0\n",
      "   🔍 Debug: Layer 0 output shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 0 output stats: mean=0.0006, std=0.0660\n",
      "   🔍 Debug: Layer 1 input shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 1 weight shape: torch.Size([10, 2048])\n",
      "   🔍 Debug: Layer 1 mask sum: 1082.0\n",
      "   🔍 Debug: Layer 1 output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Layer 1 output stats: mean=-0.0012, std=0.0137\n",
      "   🔍 Debug: Final output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Final output sample: tensor([ 0.0077, -0.0140,  0.0198,  0.0127,  0.0091], device='cuda:0')\n",
      "   📊 Initial accuracy: 1.56%\n",
      "🚀 Initialized OptimalGrowthEvolver (V2.0) with seed: [3072, 2048, 10], sparsity: 0.05\n",
      "   🔄 Neuron sorting: Enabled\n",
      "   📊 Sort frequency: Every 2 evolution steps\n",
      "\n",
      "🚀 Starting Delta-Guided Evolution for 3 steps...\n",
      "\n",
      "🧬 Evolution Step 1/3\n",
      "\n",
      "--- Analyzing Information Flow (MI) ---\n",
      "   MI Flow Detected: ['0.00', '0.00']\n",
      "No significant bottlenecks found. Evolution paused.\n",
      "   🔍 Debug: Input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Expected input dim: 3072\n",
      "   🔍 Debug: Target shape: torch.Size([64])\n",
      "   🔍 Debug: Layer 0 input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Layer 0 weight shape: torch.Size([2048, 3072])\n",
      "   🔍 Debug: Layer 0 mask sum: 315349.0\n",
      "   🔍 Debug: Layer 0 output shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 0 output stats: mean=0.0006, std=0.0660\n",
      "   🔍 Debug: Layer 1 input shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 1 weight shape: torch.Size([10, 2048])\n",
      "   🔍 Debug: Layer 1 mask sum: 1082.0\n",
      "   🔍 Debug: Layer 1 output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Layer 1 output stats: mean=-0.0012, std=0.0137\n",
      "   🔍 Debug: Final output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Final output sample: tensor([ 0.0077, -0.0140,  0.0198,  0.0127,  0.0091], device='cuda:0')\n",
      "📊 Accuracy after step 1: 1.56%\n",
      "\n",
      "🧬 Evolution Step 2/3\n",
      "   🔄 Performing neuron sorting maintenance...\n",
      "\n",
      "--- Analyzing Information Flow (MI) ---\n",
      "   MI Flow Detected: ['0.00', '0.00']\n",
      "No significant bottlenecks found. Evolution paused.\n",
      "   🔍 Debug: Input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Expected input dim: 3072\n",
      "   🔍 Debug: Target shape: torch.Size([64])\n",
      "   🔍 Debug: Layer 0 input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Layer 0 weight shape: torch.Size([2048, 3072])\n",
      "   🔍 Debug: Layer 0 mask sum: 315349.0\n",
      "   🔍 Debug: Layer 0 output shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 0 output stats: mean=0.0006, std=0.0660\n",
      "   🔍 Debug: Layer 1 input shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 1 weight shape: torch.Size([10, 2048])\n",
      "   🔍 Debug: Layer 1 mask sum: 1082.0\n",
      "   🔍 Debug: Layer 1 output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Layer 1 output stats: mean=-0.0012, std=0.0137\n",
      "   🔍 Debug: Final output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Final output sample: tensor([ 0.0077, -0.0140,  0.0198,  0.0127,  0.0091], device='cuda:0')\n",
      "📊 Accuracy after step 2: 1.56%\n",
      "\n",
      "🧬 Evolution Step 3/3\n",
      "\n",
      "--- Analyzing Information Flow (MI) ---\n",
      "   MI Flow Detected: ['0.00', '0.00']\n",
      "No significant bottlenecks found. Evolution paused.\n",
      "   🔍 Debug: Input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Expected input dim: 3072\n",
      "   🔍 Debug: Target shape: torch.Size([64])\n",
      "   🔍 Debug: Layer 0 input shape: torch.Size([64, 3072])\n",
      "   🔍 Debug: Layer 0 weight shape: torch.Size([2048, 3072])\n",
      "   🔍 Debug: Layer 0 mask sum: 315349.0\n",
      "   🔍 Debug: Layer 0 output shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 0 output stats: mean=0.0006, std=0.0660\n",
      "   🔍 Debug: Layer 1 input shape: torch.Size([64, 2048])\n",
      "   🔍 Debug: Layer 1 weight shape: torch.Size([10, 2048])\n",
      "   🔍 Debug: Layer 1 mask sum: 1082.0\n",
      "   🔍 Debug: Layer 1 output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Layer 1 output stats: mean=-0.0012, std=0.0137\n",
      "   🔍 Debug: Final output shape: torch.Size([64, 10])\n",
      "   🔍 Debug: Final output sample: tensor([ 0.0077, -0.0140,  0.0198,  0.0127,  0.0091], device='cuda:0')\n",
      "📊 Accuracy after step 3: 1.56%\n",
      "\n",
      "✅ Evolution complete!\n",
      "📈 Evolution history:\n",
      "   1. Performed neuron sorting at evolution step 2\n"
     ]
    }
   ],
   "source": [
    "!pixi run CUDA_VISIBLE_DEVICES=1 pixi run python ./experiments/hybrid_growth_experiment.py --load-model ./data/promising_models/20250707_020152/model_cifar10_3layers_seed9_acc0.47_patch0.345_sparse0.050_BEST_ACCURACY_GLOBAL.pt --evolution-steps 3 --sort-frequency 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa4d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! Physical GPU 1 ('NVIDIA GeForce RTX 2060 SUPER') is now active as PyTorch device 'cuda:0'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "def setup_correct_device(physical_gpu_id):\n",
    "    \"\"\"\n",
    "    Correctly selects a physical GPU and makes it the ONLY one visible to PyTorch.\n",
    "    This function preserves the mapping you expect.\n",
    "    \"\"\"\n",
    "    # 1. Set the environment variable using the physical ID.\n",
    "    #    This MUST be done before any torch.cuda calls.\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(physical_gpu_id)\n",
    "\n",
    "    # 2. Now that PyTorch only sees one GPU, it will always be 'cuda:0'.\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the name to confirm we got the right one.\n",
    "        gpu_name = torch.cuda.get_device_name(0) \n",
    "        print(f\"✅ Success! Physical GPU {physical_gpu_id} ('{gpu_name}') is now active as PyTorch device 'cuda:0'.\")\n",
    "        return torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"⚠️ CUDA not available. Falling back to CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = setup_correct_device(1)\n",
    "\n",
    "def inspect_checkpoint(checkpoint_path):\n",
    "    \"\"\"Comprehensive checkpoint inspector\"\"\"\n",
    "    print(f\"\\n🔍 Inspecting: {checkpoint_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    # 1. Basic info\n",
    "    print(\"\\n📋 Checkpoint Keys:\")\n",
    "    for key in checkpoint.keys():\n",
    "        if isinstance(checkpoint[key], torch.Tensor):\n",
    "            print(f\"  {key}: {checkpoint[key].shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {checkpoint[key]}\")\n",
    "    \n",
    "    # 2. Model state dict analysis\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        print(\"\\n🏗️  Model Architecture:\")\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        \n",
    "        # Analyze layers\n",
    "        layers = {}\n",
    "        for key, tensor in state_dict.items():\n",
    "            layer_name = key.split('.')[0]\n",
    "            if layer_name not in layers:\n",
    "                layers[layer_name] = {}\n",
    "            layers[layer_name][key] = tensor\n",
    "        \n",
    "        for layer_name in sorted(layers.keys()):\n",
    "            print(f\"\\n  Layer {layer_name}:\")\n",
    "            for key, tensor in layers[layer_name].items():\n",
    "                print(f\"    {key}: {tensor.shape}\")\n",
    "                \n",
    "                # Statistics for weights\n",
    "                if 'weight' in key:\n",
    "                    non_zero = (tensor != 0).sum().item()\n",
    "                    total = tensor.numel()\n",
    "                    sparsity = 1 - (non_zero / total)\n",
    "                    print(f\"      Non-zero: {non_zero}/{total} (sparsity: {sparsity:.2%})\")\n",
    "                    print(f\"      Stats: mean={tensor.mean():.4f}, std={tensor.std():.4f}\")\n",
    "                    print(f\"      Range: [{tensor.min():.4f}, {tensor.max():.4f}]\")\n",
    "    \n",
    "    # 3. Training info\n",
    "    print(\"\\n📊 Training Info:\")\n",
    "    for key in ['accuracy', 'epoch', 'loss', 'sparsity']:\n",
    "        if key in checkpoint:\n",
    "            print(f\"  {key}: {checkpoint[key]}\")\n",
    "    \n",
    "    # 4. Architecture if available\n",
    "    if 'architecture' in checkpoint:\n",
    "        print(f\"\\n🏛️  Architecture: {checkpoint['architecture']}\")\n",
    "    \n",
    "    # 5. Any optimizer state\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        print(\"\\n📈 Optimizer state: Present\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Quick usage function\n",
    "def quick_inspect(path):\n",
    "    \"\"\"Just the essentials\"\"\"\n",
    "    ckpt = torch.load(path, map_location='cpu')\n",
    "    print(f\"\\n{path.split('/')[-1]}:\")\n",
    "    print(f\"  Keys: {list(ckpt.keys())}\")\n",
    "    if 'accuracy' in ckpt:\n",
    "        print(f\"  Accuracy: {ckpt['accuracy']}\")\n",
    "    if 'architecture' in ckpt:\n",
    "        print(f\"  Architecture: {ckpt['architecture']}\")\n",
    "    if 'model_state_dict' in ckpt:\n",
    "        total_params = sum(p.numel() for p in ckpt['model_state_dict'].values() if 'weight' in p)\n",
    "        print(f\"  Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d87e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Inspecting: data/promising_models/20250707_020152/model_cifar10_3layers_seed9_acc0.47_patch0.345_sparse0.050_BEST_ACCURACY_GLOBAL.pt\n",
      "============================================================\n",
      "\n",
      "📋 Checkpoint Keys:\n",
      "  model_state_dict: OrderedDict([('0.mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])), ('0.linear.weight', tensor([[0., -0., -0.,  ..., 0., -0., 0.],\n",
      "        [0., -0., -0.,  ..., 0., 0., -0.],\n",
      "        [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [-0., -0., 0.,  ..., -0., -0., -0.],\n",
      "        [-0., -0., 0.,  ..., -0., -0., 0.],\n",
      "        [0., 0., 0.,  ..., -0., -0., -0.]])), ('0.linear.bias', tensor([0.0137, 0.0165, 0.0170,  ..., 0.0012, 0.0162, 0.0020])), ('2.mask', tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])), ('2.linear.weight', tensor([[-0.0111,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0058, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        [-0.0008, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]])), ('2.linear.bias', tensor([ 0.0069, -0.0100,  0.0202,  0.0095,  0.0084,  0.0128, -0.0217, -0.0073,\n",
      "        -0.0153, -0.0104]))])\n",
      "  architecture: [3072, 2048, 10]\n",
      "  seed: 9\n",
      "  sparsity: 0.05\n",
      "  epoch: 5\n",
      "  optimizer_state_dict: None\n",
      "  accuracy: 0.4735\n",
      "  patchability_score: 0.34508715820312497\n",
      "  extrema_counts: 0.6554361979166666\n",
      "  efficiency: 7.49921523523779e-08\n",
      "  neuron_sorting_enabled: True\n",
      "  sort_frequency: 5\n",
      "  training_epochs: 5\n",
      "  dead_neurons: 0\n",
      "  saturated_neurons: 0\n",
      "  activation_patterns: None\n",
      "  torch_version: 2.5.1+cu121\n",
      "  random_state: torch.Size([5056])\n",
      "  cuda_random_state: torch.Size([16])\n",
      "\n",
      "🏗️  Model Architecture:\n",
      "\n",
      "  Layer 0:\n",
      "    0.mask: torch.Size([2048, 3072])\n",
      "    0.linear.weight: torch.Size([2048, 3072])\n",
      "      Non-zero: 315349/6291456 (sparsity: 94.99%)\n",
      "      Stats: mean=-0.0000, std=0.0023\n",
      "      Range: [-0.0180, 0.0180]\n",
      "    0.linear.bias: torch.Size([2048])\n",
      "\n",
      "  Layer 2:\n",
      "    2.mask: torch.Size([10, 2048])\n",
      "    2.linear.weight: torch.Size([10, 2048])\n",
      "      Non-zero: 1082/20480 (sparsity: 94.72%)\n",
      "      Stats: mean=-0.0000, std=0.0029\n",
      "      Range: [-0.0221, 0.0220]\n",
      "    2.linear.bias: torch.Size([10])\n",
      "\n",
      "📊 Training Info:\n",
      "  accuracy: 0.4735\n",
      "  epoch: 5\n",
      "  sparsity: 0.05\n",
      "\n",
      "🏛️  Architecture: [3072, 2048, 10]\n",
      "\n",
      "📈 Optimizer state: Present\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_466749/2165641061.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"data/promising_models/20250707_020152/model_cifar10_3layers_seed9_acc0.47_patch0.345_sparse0.050_BEST_ACCURACY_GLOBAL.pt\"\n",
    "inspect_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7b1fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! Physical GPU 1 ('NVIDIA GeForce RTX 2060 SUPER') is now active as PyTorch device 'cuda:0'.\n",
      "Checkpoint claims accuracy: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_466749/1060586722.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\". \n\tUnexpected key(s) in state_dict: \"0.mask\", \"0.linear.weight\", \"0.linear.bias\", \"2.mask\", \"2.linear.weight\", \"2.linear.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m         model.add_module(\u001b[38;5;28mstr\u001b[39m(i*\u001b[32m2\u001b[39m+\u001b[32m1\u001b[39m), nn.ReLU())\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Load weights EXACTLY as saved\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_state_dict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[32m     21\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/structure_net/.pixi/envs/default/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\". \n\tUnexpected key(s) in state_dict: \"0.mask\", \"0.linear.weight\", \"0.linear.bias\", \"2.mask\", \"2.linear.weight\", \"2.linear.bias\". "
     ]
    }
   ],
   "source": [
    "# Test EXACTLY as the hunter would\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = setup_correct_device(1)\n",
    "# Load checkpoint\n",
    "ckpt = torch.load(checkpoint_path)\n",
    "print(f\"Checkpoint claims accuracy: {ckpt.get('accuracy', 'NOT FOUND')}\")\n",
    "\n",
    "# Recreate EXACT model from hunter\n",
    "model = nn.Sequential()\n",
    "arch = ckpt['architecture']\n",
    "for i in range(len(arch)-1):\n",
    "    model.add_module(str(i*2), nn.Linear(arch[i], arch[i+1]))\n",
    "    if i < len(arch)-2:\n",
    "        model.add_module(str(i*2+1), nn.ReLU())\n",
    "\n",
    "# Load weights EXACTLY as saved\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "# Test it\n",
    "model.eval()\n",
    "# ... test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2bed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! Physical GPU 1 ('NVIDIA GeForce RTX 2060 SUPER') is now active as PyTorch device 'cuda:0'.\n",
      "Using device: cuda:0\n",
      "Files already downloaded and verified\n",
      "Testing model on CIFAR-10...\n",
      "\n",
      "✅ Model loaded! Architecture: [3072, 2048, 10]\n",
      "📊 Claimed accuracy: 47.35%\n",
      "🔍 Actual tested accuracy: 9.76%\n",
      "❓ Match? False\n",
      "\n",
      "🚨 Accuracy suspiciously low! Debugging...\n",
      "0.linear.weight device: cuda:0\n",
      "0.linear.bias device: cuda:0\n",
      "2.linear.weight device: cuda:0\n",
      "2.linear.bias device: cuda:0\n",
      "0.mask device: cuda:0\n",
      "2.mask device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "device = setup_correct_device(1)\n",
    "# Set CUDA devices BEFORE importing torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\" # This is fine, but for simplicity let's let PyTorch manage it\n",
    "\n",
    "class SparseLayer(nn.Module):\n",
    "    \"\"\"Matches what the hunter used\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        # Initialize mask properly\n",
    "        self.register_buffer('mask', torch.ones(out_features, in_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # The mask will be on the same device as the weight because both are part of the model\n",
    "        return F.linear(x, self.linear.weight * self.mask, self.linear.bias)\n",
    "\n",
    "# CIFAR-10 test loader\n",
    "def get_cifar10_test_loader(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=False,\n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint_path = \"./data/promising_models/20250707_020152/model_cifar10_3layers_seed9_acc0.47_patch0.345_sparse0.050_BEST_ACCURACY_GLOBAL.pt\"\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load to CPU first to prevent device mismatches during loading\n",
    "# Using weights_only=True is safer for untrusted files\n",
    "ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "# Build model\n",
    "arch = ckpt['architecture']\n",
    "model = nn.Sequential()\n",
    "\n",
    "for i in range(len(arch)-1):\n",
    "    layer = SparseLayer(arch[i], arch[i+1])\n",
    "    \n",
    "    # Get keys for the state dict\n",
    "    weight_key = f'{i*2}.linear.weight'\n",
    "    bias_key = f'{i*2}.linear.bias'\n",
    "    mask_key = f'{i*2}.mask'\n",
    "    \n",
    "    # Load the weights and mask data\n",
    "    if weight_key in ckpt['model_state_dict']:\n",
    "        layer.linear.weight.data = ckpt['model_state_dict'][weight_key]\n",
    "        layer.linear.bias.data = ckpt['model_state_dict'][bias_key]\n",
    "        \n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Load data INTO the buffer, don't replace the buffer object itself.\n",
    "        layer.mask.data = ckpt['model_state_dict'][mask_key]\n",
    "    \n",
    "    model.add_module(str(i*2), layer)\n",
    "    if i < len(arch)-2:\n",
    "        model.add_module(str(i*2+1), nn.ReLU())\n",
    "\n",
    "# NOW move the entire model (including registered buffers) to the correct device\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Get test loader\n",
    "test_loader = get_cifar10_test_loader()\n",
    "\n",
    "# Test accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "print(\"Testing model on CIFAR-10...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # Move data for the current batch to the device\n",
    "        data = data.view(data.size(0), -1).to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += len(target)\n",
    "        \n",
    "        # Optional: Break early for a quick check\n",
    "        # if total >= 1000:\n",
    "        #     break\n",
    "\n",
    "actual_accuracy = correct / total\n",
    "print(f\"\\n✅ Model loaded! Architecture: {ckpt['architecture']}\")\n",
    "print(f\"📊 Claimed accuracy: {ckpt['accuracy']:.2%}\")\n",
    "print(f\"🔍 Actual tested accuracy: {actual_accuracy:.2%}\")\n",
    "print(f\"❓ Match? {abs(actual_accuracy - ckpt['accuracy']) < 0.05}\")\n",
    "\n",
    "if actual_accuracy < 0.1:\n",
    "    print(\"\\n🚨 Accuracy suspiciously low! Debugging...\")\n",
    "    # Add device check to confirm the fix\n",
    "    for name, p in model.named_parameters():\n",
    "        print(f\"{name} device: {p.device}\")\n",
    "    for name, b in model.named_buffers():\n",
    "        print(f\"{name} device: {b.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a0d4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Debugging weight statistics:\n",
      "0.linear.weight:\n",
      "  Shape: torch.Size([2048, 3072])\n",
      "  Non-zero: 315349/6291456 (5.01%)\n",
      "  Mean: -0.000002, Std: 0.002333\n",
      "  Max: 0.018042, Min: -0.018042\n",
      "2.linear.weight:\n",
      "  Shape: torch.Size([10, 2048])\n",
      "  Non-zero: 1082/20480 (5.28%)\n",
      "  Mean: -0.000019, Std: 0.002931\n",
      "  Max: 0.021964, Min: -0.022068\n",
      "\n",
      "🔍 Debugging mask statistics:\n",
      "0.mask: 315349.0/6291456 active (5.01%)\n",
      "2.mask: 1082.0/20480 active (5.28%)\n",
      "\n",
      "🔍 Testing raw output:\n",
      "After layer 0: mean=0.001343, std=0.129675\n",
      "After ReLU: mean=0.052195, std=0.075405\n",
      "Final output: tensor([[ 0.0064, -0.0011,  0.0100,  0.0042, -0.0057, -0.0154, -0.0239, -0.0168,\n",
      "         -0.0139, -0.0348]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Debug the loaded weights\n",
    "print(\"\\n🔍 Debugging weight statistics:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        non_zero = (param != 0).sum().item()\n",
    "        total = param.numel()\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Shape: {param.shape}\")\n",
    "        print(f\"  Non-zero: {non_zero}/{total} ({non_zero/total*100:.2f}%)\")\n",
    "        print(f\"  Mean: {param.mean():.6f}, Std: {param.std():.6f}\")\n",
    "        print(f\"  Max: {param.max():.6f}, Min: {param.min():.6f}\")\n",
    "\n",
    "# Also check the masks\n",
    "print(\"\\n🔍 Debugging mask statistics:\")\n",
    "for name, module in model.named_modules():\n",
    "    if hasattr(module, 'mask'):\n",
    "        mask = module.mask\n",
    "        active = mask.sum().item()\n",
    "        total = mask.numel()\n",
    "        print(f\"{name}.mask: {active}/{total} active ({active/total*100:.2f}%)\")\n",
    "\n",
    "# Test with the actual weights as they are\n",
    "print(\"\\n🔍 Testing raw output:\")\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 3072).to(device)\n",
    "    layer0_out = model[0](test_input)\n",
    "    print(f\"After layer 0: mean={layer0_out.mean():.6f}, std={layer0_out.std():.6f}\")\n",
    "    layer1_out = F.relu(layer0_out)\n",
    "    print(f\"After ReLU: mean={layer1_out.mean():.6f}, std={layer1_out.std():.6f}\")\n",
    "    final_out = model[2](layer1_out)\n",
    "    print(f\"Final output: {final_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f47c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checkpoint architecture analysis:\n",
      "Architecture from metadata: [3072, 2048, 10]\n",
      "\n",
      "Actual layers in state dict:\n",
      "  Layer 0: torch.Size([2048, 3072])\n",
      "  Layer 2: torch.Size([10, 2048])\n",
      "\n",
      "⚠️ Architecture has 3 values = 2 layers, but filename says '3layers'\n",
      "This might be a naming inconsistency.\n"
     ]
    }
   ],
   "source": [
    "# Print what's actually in the checkpoint\n",
    "print(\"🔍 Checkpoint architecture analysis:\")\n",
    "print(f\"Architecture from metadata: {ckpt['architecture']}\")\n",
    "print(\"\\nActual layers in state dict:\")\n",
    "for key in sorted(ckpt['model_state_dict'].keys()):\n",
    "    if 'weight' in key:\n",
    "        layer_idx = key.split('.')[0]\n",
    "        shape = ckpt['model_state_dict'][key].shape\n",
    "        print(f\"  Layer {layer_idx}: {shape}\")\n",
    "\n",
    "# The architecture [3072, 2048, 10] only has 2 layers!\n",
    "# But the filename says 3 layers...\n",
    "\n",
    "# Let's try assuming there's a missing middle layer\n",
    "# Maybe the architecture should be [3072, ?, ?, 10]?\n",
    "\n",
    "# Check if this is actually a 2-layer network mislabeled as 3\n",
    "if len(ckpt['architecture']) == 3:\n",
    "    print(\"\\n⚠️ Architecture has 3 values = 2 layers, but filename says '3layers'\")\n",
    "    print(\"This might be a naming inconsistency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3a1b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Plain 2-layer model accuracy: 8.12%\n"
     ]
    }
   ],
   "source": [
    "# Just load it as a 2-layer network and test\n",
    "model_2layer = nn.Sequential(\n",
    "    nn.Linear(3072, 2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2048, 10)\n",
    ")\n",
    "\n",
    "# Load the weights (without masks for now)\n",
    "model_2layer[0].weight.data = ckpt['model_state_dict']['0.linear.weight']\n",
    "model_2layer[0].bias.data = ckpt['model_state_dict']['0.linear.bias']\n",
    "model_2layer[2].weight.data = ckpt['model_state_dict']['2.linear.weight']\n",
    "model_2layer[2].bias.data = ckpt['model_state_dict']['2.linear.bias']\n",
    "\n",
    "model_2layer = model_2layer.to(device)\n",
    "model_2layer.eval()\n",
    "\n",
    "# Quick test\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        if i >= 10:  # Just 10 batches\n",
    "            break\n",
    "        data = data.view(data.size(0), -1).to(device)\n",
    "        output = model_2layer(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target.to(device)).sum().item()\n",
    "\n",
    "print(f\"\\n🎯 Plain 2-layer model accuracy: {correct/640:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae55a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing modular structure_net...\n",
      "✅ Network created: 3 layers\n",
      "✅ Network stats: [784, 128, 10]\n",
      "✅ LSUV initialization successful\n",
      "🎯 All modular components working!\n"
     ]
    }
   ],
   "source": [
    "from src.structure_net import create_standard_network, get_network_stats, lsuv_init_network\n",
    "import torch\n",
    "\n",
    "print('🧪 Testing modular structure_net...')\n",
    "\n",
    "# Test network creation\n",
    "network = create_standard_network([784, 128, 10], 0.02, device='cpu')\n",
    "print(f'✅ Network created: {len(network)} layers')\n",
    "\n",
    "# Test network stats\n",
    "stats = get_network_stats(network)\n",
    "print(f'✅ Network stats: {stats[\"architecture\"]}')\n",
    "\n",
    "# Test LSUV\n",
    "sample_batch = torch.randn(32, 784)\n",
    "lsuv_init_network(network, sample_batch, verbose=False)\n",
    "print('✅ LSUV initialization successful')\n",
    "\n",
    "print('🎯 All modular components working!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
